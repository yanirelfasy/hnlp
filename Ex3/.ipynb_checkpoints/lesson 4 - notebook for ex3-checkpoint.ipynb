{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables comparing stanza and YAP for Hebrew text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stanza'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-42a45a4a69ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stanza'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import stanza\n",
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "from pandas.io.json import json_normalize\n",
    "sys.path.append(\"C:/Users/fyuva/projects/2021/hebrew-nlp-workshop/scripts/yap_wrapper\")\n",
    "from yap_api import YapApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor:\n",
    "    def __init__(self):\n",
    "        self.heb_nlp = stanza.Pipeline(lang='he', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "        #replace MY_TOKEN with the token you got from the langndata website\n",
    "        self.yap_token=\"MY_TOKEN\"\n",
    "        self.ip='127.0.0.1:8000'\n",
    "        self.yap=YapApi() \n",
    "    \n",
    "    def print_stanza_analysis(self, text):\n",
    "        text += \" XX\"\n",
    "        doc=self.heb_nlp(text)\n",
    "        lst=[]\n",
    "        for sen in doc.sentences:\n",
    "            for token in sen.tokens:\n",
    "                for word in token.words:\n",
    "                    features=[(word.text,\n",
    "                               word.lemma,\n",
    "                               word.upos,\n",
    "                               word.xpos,\n",
    "                               word.head,\n",
    "                               word.deprel,\n",
    "                               word.feats)]\n",
    "\n",
    "                    df=pd.DataFrame(features, columns=[\"text\", \"lemma\", \"upos\", \"xpos\", \"head\", \"deprel\",\"feats\"])\n",
    "                    lst.append(df)\n",
    "        tot_df=pd.concat(lst, ignore_index=True)\n",
    "        tot_df=tot_df.shift(1).iloc[1:]\n",
    "        tot_df[\"head\"]=tot_df[\"head\"].astype(int)\n",
    "        print(tot_df.head(50))\n",
    "        \n",
    "    def print_yap_analysis(self, text):\n",
    "        text= text.replace(r'\"', r'\\\"')\n",
    "        tokenized_text, segmented_text, lemmas, dep_tree, md_lattice, ma_lattice=self.yap.run(text, self.ip)                 \n",
    "        dep_tree.set_index(\"num\",inplace=True)\n",
    "        print(dep_tree)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-05 18:52:53 INFO: Loading these models for language: he (Hebrew):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | htb     |\n",
      "| mwt       | htb     |\n",
      "| pos       | htb     |\n",
      "| lemma     | htb     |\n",
      "| depparse  | htb     |\n",
      "=======================\n",
      "\n",
      "2021-05-05 18:52:53 INFO: Use device: cpu\n",
      "2021-05-05 18:52:53 INFO: Loading: tokenize\n",
      "2021-05-05 18:52:53 INFO: Loading: mwt\n",
      "2021-05-05 18:52:53 INFO: Loading: pos\n",
      "2021-05-05 18:52:54 INFO: Loading: lemma\n",
      "2021-05-05 18:52:54 INFO: Loading: depparse\n",
      "2021-05-05 18:52:55 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stanza\n",
      "      text   lemma   upos   xpos  head     deprel  \\\n",
      "1     בתוך    בתוך    ADP    ADP     2       case   \n",
      "2      שער     שער   NOUN   NOUN     0       root   \n",
      "3     ראשה    ראשה  PROPN  PROPN     2  flat:name   \n",
      "4        ה       ה    DET    DET     5    det:def   \n",
      "5    לבינה   לבינה   NOUN   NOUN     2       nmod   \n",
      "6        ה       ה    DET    DET     7    det:def   \n",
      "7   ציפורן  ציפורן   NOUN   NOUN     5       amod   \n",
      "8        ו       ו  CCONJ  CCONJ     9         cc   \n",
      "9       כף      כף   VERB   VERB     2       conj   \n",
      "10     ידה     ידה   NOUN   NOUN     9        obj   \n",
      "11    קטנה     קטן    ADJ    ADJ    10       amod   \n",
      "12       ה       ה  SCONJ  SCONJ    13       mark   \n",
      "13   לבינה    הבין   VERB   VERB    10  acl:relcl   \n",
      "14       ב       ב    ADP    ADP    15       case   \n",
      "15     יד_      יד   NOUN   NOUN    13        obl   \n",
      "16    _של_      של    ADP    ADP    17   case:gen   \n",
      "17    _הוא     הוא   PRON   PRON    15  nmod:poss   \n",
      "\n",
      "                                                feats  \n",
      "1                                                None  \n",
      "2                             Gender=Masc|Number=Sing  \n",
      "3                                                None  \n",
      "4                                        PronType=Art  \n",
      "5                              Gender=Fem|Number=Sing  \n",
      "6                                        PronType=Art  \n",
      "7                             Gender=Masc|Number=Sing  \n",
      "8                                                None  \n",
      "9   Gender=Fem|HebBinyan=PAAL|Number=Sing|Person=3...  \n",
      "10                             Gender=Fem|Number=Sing  \n",
      "11                             Gender=Fem|Number=Sing  \n",
      "12                                               None  \n",
      "13  Gender=Fem|HebBinyan=PAAL|Number=Sing|Person=1...  \n",
      "14                                               None  \n",
      "15                Definite=Def|Gender=Fem|Number=Sing  \n",
      "16                                               None  \n",
      "17  Case=Gen|Gender=Masc|Number=Sing|Person=3|Pron...  \n",
      "------------------------\n",
      "yap\n",
      "Start Yap call\n",
      "Tokens: 10\n",
      "End Yap call 0 /0\n",
      "       word   lemma          pos        pos_2  \\\n",
      "num                                             \n",
      "1      בתוך    בתוך           IN           IN   \n",
      "2       שער     שער          NNT          NNT   \n",
      "3      ראשה     ראש           NN           NN   \n",
      "4    הלבינה   הלבין           VB           VB   \n",
      "5         ה       ה          DEF          DEF   \n",
      "6    ציפורן  ציפורן           NN           NN   \n",
      "7         ו       ו         CONJ         CONJ   \n",
      "8        כף      כף          NNT          NNT   \n",
      "9       ידה      יד           NN           NN   \n",
      "10     קטנה     קטן           JJ           JJ   \n",
      "11   הלבינה   הלבין           VB           VB   \n",
      "12        ב       ב  PREPOSITION  PREPOSITION   \n",
      "13      ידו      יד           NN           NN   \n",
      "\n",
      "                                         empty dependency_arc dependency_part  \\\n",
      "num                                                                             \n",
      "1                                                           4         prepmod   \n",
      "2                                  gen=M|num=S              1            pobj   \n",
      "3    gen=M|num=S|suf_gen=F|suf_num=S|suf_per=3              2            gobj   \n",
      "4                 gen=F|num=S|per=3|tense=PAST              7            conj   \n",
      "5                                                           6             def   \n",
      "6                                  gen=F|num=S              4            subj   \n",
      "7                                                           0            ROOT   \n",
      "8                                  gen=F|num=S             11            subj   \n",
      "9    gen=F|num=S|suf_gen=F|suf_num=S|suf_per=3              8            gobj   \n",
      "10                                 gen=F|num=S              8            amod   \n",
      "11                gen=F|num=S|per=3|tense=PAST              7            conj   \n",
      "12                                                         11         prepmod   \n",
      "13   gen=F|num=S|suf_gen=M|suf_num=S|suf_per=3             12            pobj   \n",
      "\n",
      "    dependency_arc_2 dependency_part_2  \n",
      "num                                     \n",
      "1                  _                 _  \n",
      "2                  _                 _  \n",
      "3                  _                 _  \n",
      "4                  _                 _  \n",
      "5                  _                 _  \n",
      "6                  _                 _  \n",
      "7                  _                 _  \n",
      "8                  _                 _  \n",
      "9                  _                 _  \n",
      "10                 _                 _  \n",
      "11                 _                 _  \n",
      "12                 _                 _  \n",
      "13                 _                 _  \n",
      "Program end\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"\n",
    "בתוך שער ראשה הלבינה הציפורן וכף ידה קטנה הלבינה בידו\n",
    "\"\"\"\n",
    "processor=Processor()\n",
    "print(\"stanza\")\n",
    "processor.print_stanza_analysis(text)\n",
    "print(\"------------------------\")\n",
    "print(\"yap\")\n",
    "processor.print_yap_analysis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hebnlp",
   "language": "python",
   "name": "hebnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
